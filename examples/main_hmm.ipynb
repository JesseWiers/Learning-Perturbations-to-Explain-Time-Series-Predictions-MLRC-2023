{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is designed to train a state classifier on the HMM dataset and evaluate the performance of various explainability methods.\n",
    "\n",
    "The script allows for the training of a StateClassifierNet using the PyTorch Lightning framework and evaluates the model using different attribution methods provided by the 'tint' library. The explainers include DeepLift, GradientShap, IntegratedGradients, Lime, and several others specifically designed for temporal data.\n",
    "\n",
    "The main function orchestrates the training process, the application of explainers, and the evaluation of the model's predictions. It also handles deterministic training, device configuration, and logging.\n",
    "\n",
    "The results of the explainability methods are saved to a CSV file, which includes metrics such as AUP (Area Under Precision), AUR (Area Under Recall), information gain, entropy for the true saliency of the test data.\n",
    "\n",
    "Parameters:\n",
    "    explainers (List[str]): List of explainers to use for model interpretation.\n",
    "    device (str): Device to use for computation (default is \"cpu\").\n",
    "    fold (int): Fold index for cross-validation.\n",
    "    seed (int): Seed for random number generation to ensure reproducibility.\n",
    "    deterministic (bool): Flag to set training to be deterministic.\n",
    "    lambda_1 (float): Hyperparameter lambda_1 for certain explainers.\n",
    "    lambda_2 (float): Hyperparameter lambda_2 for certain explainers.\n",
    "    output_file (str): Path to the file where results will be saved.\n",
    "    rnn (str): Type of RNN to use within the model (default is \"gru\").\n",
    "    preservation_mode (bool): Flag to indicate whether to use preservation mode in certain explainers.\n",
    "\n",
    "Example:\n",
    "    To run the script from the command line, you can use arguments like so:\n",
    "    python main.py --explainers deep_lift gradient_shap --device cuda:0 --fold 1 --seed 123 --deterministic --lambda_1 0.5 --lambda_2 0.5 --output_file \"my_results.csv\"\n",
    "\n",
    "This will train the classifier, apply the specified explainers, and save the results to \"my_results.csv\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp drive/MyDrive/time_interpret.zip sample_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following allows you to run the main for hmm\n",
    "\n",
    "!python3 time_interpret/experiments/hmm/main.py --explainers deep_lift gradient_shap --device cuda:0 --fold 1 --seed 42 --deterministic --lambda_1 1 --lambda_2 1 --output_file \"my_results.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_interpret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
