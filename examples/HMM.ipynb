{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fcb893",
   "metadata": {},
   "source": [
    "# HMM Experiment example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc365a",
   "metadata": {},
   "source": [
    "In this example, we will use the HMM dataset provided by this package, get some attributions,\n",
    "and evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131df67",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ed6f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'experiments'"
     ]
    }
   ],
   "source": [
    "# from experiments import *\n",
    "import sys\n",
    "sys.path.insert(0, './')\n",
    "from experiments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf20266a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HMM\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwhite_box\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aur\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexperiments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhmm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StateClassifierNet\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'experiments'"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "from tint.attr import TemporalAugmentedOcclusion, TimeForwardTunnel\n",
    "from tint.datasets import HMM\n",
    "from tint.metrics.white_box import aur\n",
    "\n",
    "from experiments.hmm.classifier import StateClassifierNet\n",
    "\n",
    "hmm = HMM()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a1117",
   "metadata": {},
   "source": [
    "### Make reproducible experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06292c",
   "metadata": {},
   "source": [
    "For this example, we will make everything reproducible. With this aim, we use the \n",
    "tool from Pytorch-Lightning: seed_everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455bd164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "seed_everything(seed=seed, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50bb6c",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30d964",
   "metadata": {},
   "source": [
    "We load the HMM (Hidden Markov Model) dataset, and eventually download it (since arma is a synthetic dataset, \n",
    "download actually generates the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb4db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape torch.Size([800, 200, 3])\n",
      "y_train.shape torch.Size([800, 200])\n",
      "x_test.shape torch.Size([200, 200, 3])\n",
      "y_test.shape torch.Size([200, 200])\n"
     ]
    }
   ],
   "source": [
    "x_train = hmm.preprocess(split=\"train\")[\"x\"]\n",
    "y_train = hmm.preprocess(split=\"train\")[\"y\"]\n",
    "\n",
    "x_test = hmm.preprocess(split=\"test\")[\"x\"]\n",
    "y_test = hmm.preprocess(split=\"test\")[\"y\"]\n",
    "\n",
    "print(\"x_train.shape\", x_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "\n",
    "print(\"x_test.shape\", x_test.shape)\n",
    "print(\"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2918d99e",
   "metadata": {},
   "source": [
    "### Create and train a simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4067b",
   "metadata": {},
   "source": [
    "We will now train a simple classifier (a GRU followed by a MLP) over the HMM dataset.\n",
    "This dataset provides indeed labels, generated given the hidden states of the HMM.\n",
    "\n",
    "We use the Pytorch-Lightning framework to efficiently train this model. Here, the \n",
    "accelerator is set to ``cpu``, but feel free to change this to ``gpu``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0beb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = StateClassifierNet(\n",
    "    feature_size=3,\n",
    "    n_state=2,\n",
    "    hidden_size=200,\n",
    "    regres=True,\n",
    "    loss=\"cross_entropy\",\n",
    "    lr=0.0001,\n",
    "    l2=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f058fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m(\n\u001b[1;32m      2\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, accelerator\u001b[38;5;241m=\u001b[39maccelerator, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(classifier, datamodule\u001b[38;5;241m=\u001b[39mhmm)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=50, accelerator=accelerator, deterministic=True\n",
    ")\n",
    "trainer.fit(classifier, datamodule=hmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7771d",
   "metadata": {},
   "source": [
    "### Get train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d77876",
   "metadata": {},
   "source": [
    "We only compute the attributions over the test set. However, we will also need the train data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db47494",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = hmm.preprocess(split=\"train\")[\"x\"].to(accelerator)\n",
    "x_test = hmm.preprocess(split=\"test\")[\"x\"].to(accelerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a052b62",
   "metadata": {},
   "source": [
    "###Â Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde710ae",
   "metadata": {},
   "source": [
    "We set the classifer to the ``evaluation`` mode, and we push it to the current accelerator.\n",
    "\n",
    "We also disable ``cudnn`` when using ``cuda``, as it cannot backpropagate when set on evaluation.\n",
    "Please refer to https://captum.ai/docs/faq#how-can-i-resolve-cudnn-rnn-backward-error-for-rnn-or-lstm-network \n",
    "for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "621ed3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to eval\n",
    "classifier.eval()\n",
    "\n",
    "# Set model to accelerator\n",
    "classifier.to(accelerator)\n",
    "\n",
    "if accelerator == \"cuda\":\n",
    "    th.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b058fb4",
   "metadata": {},
   "source": [
    "### Create attributions using temporal augmented occlusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f283cf",
   "metadata": {},
   "source": [
    "In this example, we will use ``temporal_augmented_occlusion`` as an attribution method, first presented \n",
    "in this paper: https://arxiv.org/abs/2003.02821. This method hides some data like the ``Occlusion`` method,\n",
    "however, instead of replacing the hidden data with a baseline, it samples this baseline\n",
    "from a bootstrapped distribution. Moreover, unlike the regular ``augmented_occlusion``, this method only \n",
    "hides data from the last time, leaving the past data unchanged.\n",
    "\n",
    "We also use a special tool: ``TimeForwardTunnel``. This method allows us to compute attributions\n",
    "at each different time using only the past as information. The ``TimeForwardTunnel`` then loops over \n",
    "every time to compute every attributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "235e53be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a961c28071ce45f18fde8992feee368b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Temporal Augmented Occlusion attribution:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer = TimeForwardTunnel(\n",
    "    TemporalAugmentedOcclusion(\n",
    "        classifier, data=x_train, n_sampling=10, is_temporal=True\n",
    "    )\n",
    ")\n",
    "\n",
    "attr = explainer.attribute(\n",
    "    x_test,\n",
    "    sliding_window_shapes=(1,),\n",
    "    attributions_fn=abs,\n",
    "    task=\"binary\",\n",
    "    show_progress=True,\n",
    ").abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a90b6",
   "metadata": {},
   "source": [
    "### Attributions evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d94a26",
   "metadata": {},
   "source": [
    "Since we know the true attributions, we can evaluate our computed attributions \n",
    "using our white-box metrics. For instance, we compute here the ``aur`` (area under recall):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3fd8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true saliency\n",
    "true_saliency = hmm.true_saliency(split=\"test\").to(accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61505d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"{aur(attr, true_saliency):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11303c7d",
   "metadata": {},
   "source": [
    "This is slightly better than the results reported in https://arxiv.org/pdf/2106.05303.\n",
    "\n",
    "There are however better methods than temporal_augmented_occlusion for this task. For more details, \n",
    "please refer to our ``experiments/hmm`` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154b02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
